import torch
import torch.nn.functional as F
import numpy as np
import re
import clip
from typing import Dict, List, Tuple
from utils.box_util import box3d_iou_batch_tensor

class RewardFunctions:
    """
    Reward functions for 3D-R1 RL training
    """
    
    def __init__(self, device, clip_model_name="ViT-B/32"):
        self.device = device
        # Load CLIP for semantic similarity
        self.clip_model, self.clip_preprocess = clip.load(clip_model_name, device=device)
        
    def compute_format_reward(self, text: str) -> float:
        """
        Ensure that the content generated by the model has a resolvable structure
        """
        # Check for proper format with <think> and <answer> tags
        think_pattern = r'<think>.*?</think>'
        answer_pattern = r'<answer>.*?</answer>'
        
        has_think = bool(re.search(think_pattern, text, re.DOTALL))
        has_answer = bool(re.search(answer_pattern, text, re.DOTALL))
        
        # Check for reasonable length
        think_match = re.search(think_pattern, text, re.DOTALL)
        answer_match = re.search(answer_pattern, text, re.DOTALL)
        
        think_length = len(think_match.group()) if think_match else 0
        answer_length = len(answer_match.group()) if answer_match else 0
        
        # Reward based on format compliance
        format_score = 0.0
        if has_think and has_answer:
            format_score += 0.5
        if think_length > 20:  # Minimum reasoning length
            format_score += 0.25
        if answer_length > 10:  # Minimum answer length
            format_score += 0.25
            
        return format_score
    
    def compute_perception_reward(self, batch_data: Dict, idx: int, 
                                generated_text: str) -> float:
        """
        Accurately identifying where the relevant objects' location is
        Evaluates spatial precision using IoU metric
        """
        # Extract predicted bounding boxes from generated text
        predicted_boxes = self.extract_boxes_from_text(generated_text)
        
        # Get ground truth boxes from batch data
        if 'gt_box_corners' in batch_data:
            gt_boxes = batch_data['gt_box_corners'][idx]
        elif 'box_corners' in batch_data:
            gt_boxes = batch_data['box_corners'][idx]
        else:
            return 0.0
        
        if len(predicted_boxes) == 0 or len(gt_boxes) == 0:
            return 0.0
            
        # Compute IoU for each predicted box with ground truth
        max_ious = []
        for pred_box in predicted_boxes:
            ious = []
            for gt_box in gt_boxes:
                iou = self.compute_3d_iou(pred_box, gt_box)
                ious.append(iou)
            max_ious.append(max(ious) if ious else 0.0)
            
        # Average IoU as perception reward
        avg_iou = np.mean(max_ious) if max_ious else 0.0
        return avg_iou
    
    def compute_semantic_similarity_reward(self, generated_text: str, 
                                         ground_truth: str = None) -> float:
        """
        Encourage semantic coherence between predicted and ground truth answers
        Using CLIP text encoder
        """
        try:
            # If no ground truth provided, return 0
            if ground_truth is None:
                return 0.0
                
            # Extract answer part from generated text
            answer_match = re.search(r'<answer>(.*?)</answer>', generated_text, re.DOTALL)
            if answer_match:
                generated_answer = answer_match.group(1).strip()
            else:
                generated_answer = generated_text
                
            # Extract answer from ground truth
            gt_answer_match = re.search(r'<answer>(.*?)</answer>', ground_truth, re.DOTALL)
            if gt_answer_match:
                gt_answer = gt_answer_match.group(1).strip()
            else:
                gt_answer = ground_truth
            
            # Encode texts with CLIP
            generated_tokens = clip.tokenize([generated_answer]).to(self.device)
            gt_tokens = clip.tokenize([gt_answer]).to(self.device)
            
            with torch.no_grad():
                generated_features = self.clip_model.encode_text(generated_tokens)
                gt_features = self.clip_model.encode_text(gt_tokens)
                
                # Normalize features
                generated_features = F.normalize(generated_features, dim=-1)
                gt_features = F.normalize(gt_features, dim=-1)
                
                # Compute cosine similarity
                similarity = torch.cosine_similarity(generated_features, gt_features, dim=-1)
                
            return similarity.item()
            
        except Exception as e:
            print(f"Error computing semantic similarity: {e}")
            return 0.0
    
    def extract_boxes_from_text(self, text: str) -> List[np.ndarray]:
        """
        Extract 3D bounding boxes from generated text
        This is a simplified version - in practice, you might need more sophisticated parsing
        """
        # Look for box coordinates in the text
        # This is a placeholder - you'll need to implement based on your specific format
        boxes = []
        
        # Example pattern: "box: [x1,y1,z1,x2,y2,z2]"
        box_pattern = r'box:\s*\[([\d\.,\-\s]+)\]'
        matches = re.findall(box_pattern, text)
        
        for match in matches:
            try:
                coords = [float(x.strip()) for x in match.split(',')]
                if len(coords) == 6:  # 3D box with 2 corners
                    # Convert to 8 corners format
                    x1, y1, z1, x2, y2, z2 = coords
                    box = np.array([
                        [x1, y1, z1], [x2, y1, z1], [x2, y2, z1], [x1, y2, z1],
                        [x1, y1, z2], [x2, y1, z2], [x2, y2, z2], [x1, y2, z2]
                    ])
                    boxes.append(box)
            except:
                continue
                
        return boxes
    
    def compute_3d_iou(self, box1: np.ndarray, box2: np.ndarray) -> float:
        """
        Compute 3D IoU between two bounding boxes
        """
        # Simplified 3D IoU computation
        # In practice, you might want to use the existing box_util.box3d_iou_batch_tensor
        
        # Convert to min/max format
        min1, max1 = box1.min(axis=0), box1.max(axis=0)
        min2, max2 = box2.min(axis=0), box2.max(axis=0)
        
        # Compute intersection
        intersection_min = np.maximum(min1, min2)
        intersection_max = np.minimum(max1, max2)
        
        if np.any(intersection_min > intersection_max):
            return 0.0
            
        intersection_volume = np.prod(intersection_max - intersection_min)
        
        # Compute union
        volume1 = np.prod(max1 - min1)
        volume2 = np.prod(max2 - min2)
        union_volume = volume1 + volume2 - intersection_volume
        
        return intersection_volume / union_volume if union_volume > 0 else 0.0
    
    def compute_total_reward(self, batch_data: Dict, generated_texts: List[str], 
                           ground_truth: List[str]) -> torch.Tensor:
        """
        Compute total reward combining all reward functions
        """
        batch_size = len(generated_texts)
        rewards = torch.zeros(batch_size, device=self.device)
        
        for i in range(batch_size):
            # Format reward
            format_reward = self.compute_format_reward(generated_texts[i])
            
            # Perception reward (IoU-based)
            perception_reward = self.compute_perception_reward(
                batch_data, i, generated_texts[i]
            )
            
            # Semantic similarity reward
            semantic_reward = self.compute_semantic_similarity_reward(
                generated_texts[i], ground_truth[i]
            )
            
            # Combine rewards with weights
            total_reward = (
                format_reward * 0.3 + 
                perception_reward * 0.4 + 
                semantic_reward * 0.3
            )
            rewards[i] = total_reward
            
        return rewards
